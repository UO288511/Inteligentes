{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Practice 4.2: Neural Networks (Classification)**\n",
    "\n",
    "<hr>\n",
    "\n",
    "## **1. Introduction**\n",
    "In the previous practice, we learned how to solve regression problems using neural networks. In this session, we will explore how to solve **classification problems**.\n",
    "\n",
    "Until now, we have focused on binary classification problems, but in this practice, we will also address two new types.\n",
    "\n",
    "### **Objectives**\n",
    "In this practice, you will learn to:\n",
    "* Distinguish between different types of classification problems.\n",
    "* Modify a neural network to learn classification problems.\n",
    "* Transform categorical variables into numerical ones.\n",
    "\n",
    "Let's begin by loading our data once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seed = 2533\n",
    "data = pd.read_pickle('https://raw.githubusercontent.com/AIC-Uniovi/Sistemas-Inteligentes/refs/heads/main/datasets/f1_23_monaco.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **2. Binary Classification Problems**\n",
    "\n",
    "Let's try to solve a problem similar to the one in Practice 3 on classification, that is:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Create a model that, given the time (in seconds) of the first two sectors of an <i>Aston Martin</i> driver (<code>'Sector1Time', 'Sector2Time'</code>), predicts whether that time was set by <i>Alonso</i> or not (<i>Stroll</i>).</b>\n",
    "</div>\n",
    "\n",
    "As always, the first step is to create the necessary datasets to train a model.\n",
    "\n",
    "### **2.1. Data Preprocessing**\n",
    "\n",
    "We create the variable <code>data_aston</code> with the rows and columns needed to train our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aston = data.loc[data.Team == 'Aston Martin'][['Sector1Time', 'Sector2Time', 'Driver']].copy()\n",
    "data_aston['Sector1Time'] = data_aston['Sector1Time'].dt.total_seconds()\n",
    "data_aston['Sector2Time'] = data_aston['Sector2Time'].dt.total_seconds()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Create the <code>Class</code> column in the <code>data_aston</code> DataFrame so that it is zero whenever the driver is not Alonso, and 1 otherwise.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "data_aston['Class'] = data_aston['Driver'].apply(lambda x: 1 if x == 'ALO' else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Separate the X and Y from the <code>data_aston</code> DataFrame, split them into training and test sets (80/20) setting the random seed, and finally <b>standardize</b> the X variables.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "X = data_aston[['Sector1Time', 'Sector2Time']]\n",
    "Y = data_aston['Class']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sd = scaler.fit_transform(X_train)\n",
    "X_test_sd = scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2. Machine Learning**\n",
    "\n",
    "With the data ready, we will once again train and evaluate the machine learning models we already know, so we can compare them with our new system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Train and evaluate the remaining models (<i>Logistic Regression</i>, <i>K-Nearest Neighbors</i>, <i>Decision Trees</i>, and <i>SVC</i>) using the following function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Baseline Random:\n",
      "╭──────────┬──────────╮\n",
      "│ Metric   │     TEST │\n",
      "├──────────┼──────────┤\n",
      "│ Accuracy │ 0.478261 │\n",
      "│ F1       │ 0.5      │\n",
      "╰──────────┴──────────╯\n",
      "\n",
      "Results for Baseline Zero-R:\n",
      "╭──────────┬──────────╮\n",
      "│ Metric   │     TEST │\n",
      "├──────────┼──────────┤\n",
      "│ Accuracy │ 0.565217 │\n",
      "│ F1       │ 0.722222 │\n",
      "╰──────────┴──────────╯\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.dummy import DummyRegressor  \n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def evaluate_model(Y_test, preds_test, model_name, average = 'binary'):\n",
    "    preds_test = (preds_test >= 0.5).astype(int)\n",
    "    metrics = [\n",
    "        ('Accuracy', accuracy_score(Y_test, preds_test)),\n",
    "        ('F1', f1_score(Y_test,preds_test, average=average))\n",
    "    ]\n",
    "    \n",
    "    print(f'Results for {model_name}:')\n",
    "    print(tabulate(metrics, headers = ['Metric', 'TEST'], tablefmt = 'rounded_outline'))\n",
    "    print()\n",
    "\n",
    "# Baseline Random\n",
    "baseline_random = DummyClassifier(strategy = 'uniform')\n",
    "baseline_random.fit(X_train, Y_train)\n",
    "preds_test = baseline_random.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'Baseline Random')\n",
    "\n",
    "# Baseline Zero-R\n",
    "baseline_zero = DummyClassifier(strategy = 'most_frequent')\n",
    "baseline_zero.fit(X_train, Y_train)\n",
    "preds_test = baseline_zero.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'Baseline Zero-R')\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# KNN\n",
    "model_knn = KNeighborsRegressor()\n",
    "model_knn.fit(X_train, Y_train)\n",
    "preds_test = model_knn.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'KNN')\n",
    "\n",
    "\n",
    "# Decision Trees\n",
    "model_tree = DecisionTreeRegressor()\n",
    "model_tree.fit(X_train, Y_train)\n",
    "preds_test = model_tree.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'Decision Trees')\n",
    "\n",
    "# SVR\n",
    "model_svr = SVR()\n",
    "model_svr.fit(X_train, Y_train)\n",
    "preds_test = model_svr.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'SVR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results should look something like this:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Model                 | Accuracy (test) | F1 (test) |\n",
    "|-----------------------|-----------------|-----------|\n",
    "| Baseline Random       | 0.522           | 0.560     |\n",
    "| Baseline Zero-R       | 0.565           | 0.722     |\n",
    "| Logistic Regression   | 0.565           | 0.722     |\n",
    "| KNN                   | 0.957           | 0.963     |\n",
    "| Decision Trees        | 0.826           | 0.867     |\n",
    "| SVC                   | 0.913           | 0.929     |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Visualizing Data and Models**\n",
    "\n",
    "In this case, our problem has two inputs and one output (the class). As we saw in the regression part, working with such low dimensions allows us to visualize the behavior of the data and the models we are learning.\n",
    "\n",
    "Thanks to this possibility, we can analyze in advance whether the relationship between the inputs and outputs can be solved with linear models or, on the other hand, requires a non-linear approach.\n",
    "\n",
    "Below is the function that visualizes the data and, given a model, makes a series of predictions to draw its **decision boundary**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to visualize data and model decision boundary\n",
    "def plot_decision_boundary(X_train, Y_train, X_test, Y_test, model, model_name):\n",
    "    plt.figure(figsize = (8, 6))\n",
    "\n",
    "    # Create a mesh grid of points within the range of Train and Test data\n",
    "    x_min, x_max = min(X_train[:, 0].min(), X_test[:, 0].min()) - 0.5, max(X_train[:, 0].max(), X_test[:, 0].max()) + 0.5\n",
    "    y_min, y_max = min(X_train[:, 1].min(), X_test[:, 1].min()) - 0.5, max(X_train[:, 1].max(), X_test[:, 1].max()) + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "\n",
    "    # Predict the probability for each point in the mesh\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = model.predict(grid).reshape(xx.shape)\n",
    "\n",
    "    # Draw the decision boundary\n",
    "    contour = plt.contourf(xx, yy, Z, levels = [0, 0.5, 1], alpha = 0.7, cmap = 'coolwarm')\n",
    "\n",
    "    # Add colorbar\n",
    "    plt.colorbar(contour)\n",
    "\n",
    "    # Visualize the Train points\n",
    "    plt.scatter(X_train[:, 0], X_train[:, 1], c = Y_train, cmap = 'coolwarm', edgecolors = 'k', label = 'Train Data')\n",
    "    \n",
    "    # Visualize the Test points\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], c = Y_test, cmap = 'coolwarm', marker = 'X', label = 'Test Data')\n",
    "\n",
    "    # Labels and legend\n",
    "    plt.xlabel('Sector1Time')\n",
    "    plt.ylabel('Sector1Time')\n",
    "    plt.title(f'Decision Boundary: {model_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary(X_train, Y_train, X_test, Y_test, baseline_random, 'Baseline Random')\n",
    "plot_decision_boundary(X_train, Y_train, X_test, Y_test, baseline_zero, 'Baseline Zero-R')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Create, within the provided function, a <b>binary classification</b> neural network with a single layer. Train it and plot the evolution of the loss using the <code>plot_loss_history</code> function.\n",
    "    <hr>\n",
    "    Train with a validation set of 20%, for 200 epochs, with a batch size of 16 and a learning rate of 0.001.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Do you think the problem is linear or non-linear? Analyzing the decision boundaries, which models are non-linear?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3. Neural Network**\n",
    "\n",
    "Now we will create a neural network from scratch to solve this problem. Remember that the steps are as follows:\n",
    "\n",
    "1) Create the model architecture.\n",
    "2) Specify the optimizer, loss function, and compile.\n",
    "3) Train and evaluate.\n",
    "\n",
    "We will set the seeds and create the function to plot the model's training evolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random\n",
    "\n",
    "# Set the libraries' seeds so that the results are reproducible.\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "def plot_loss_history(history):\n",
    "    # Extract the data from the history\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss', None)  # It may not exist if validation wasn't used\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    # Create a DataFrame for seaborn\n",
    "    data = pd.DataFrame({ 'Epoch': list(epochs) * 2, 'Loss': loss + (val_loss if val_loss else []), 'Type': ['Train'] * len(loss) + (['Validation'] * len(val_loss) if val_loss else []) })\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    sns.lineplot(data = data, x = 'Epoch', y = 'Loss', hue = 'Type')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Evolution during Training')\n",
    "    plt.legend(title = 'Dataset')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Activation in the Last Layer and Loss**\n",
    "\n",
    "As mentioned in the previous practice, when creating a neural network, it is crucial to properly select both the **activation function of the last layer** and the **loss function**.\n",
    "\n",
    "In a regression problem, the last layer generally does not use an activation function to avoid limiting the predictions to a specific range. However, if the values being predicted are always positive, a *ReLU* function could be applied.\n",
    "\n",
    "<center>\n",
    "    <div style=\"border-radius:5px; padding:10px; background:white; max-width:900px\">\n",
    "        <img src=\"https://i.imgur.com/e7kd5fs.png\">   \n",
    "    </div>\n",
    "</center>\n",
    "\n",
    "Now, we are facing a **binary classification** problem, where we seek to predict a probability, i.e., a value between $0$ and $1$. Therefore, we need to use a **sigmoid** activation function in the final layer.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Note:</strong> Remember that a neural network with a <b>single</b> activation function in the last layer <b>cannot learn non-linear problems</b>; activation functions are required in the hidden layers for that.\n",
    "</div>\n",
    "\n",
    "Another aspect we need to change compared to regression problems is the **loss function**.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Note:</strong> In a binary classification problem, loss functions designed for regression, such as <b>mean absolute error</b> (MAE), should not be used, as they are oriented to problems where the outputs are <b>continuous values, not probabilities</b>.\n",
    "</div>\n",
    "\n",
    "Therefore, in addition to adding a sigmoid to the output layer, we must also change the loss function to **Binary Crossentropy**. This leaves us with the following table:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Problem Type                 | Activation Function in Last Layer           | Loss Function          | In *Keras*                                |\n",
    "|------------------------------|--------------------------------------------|------------------------|-------------------------------------------|\n",
    "| *Regression*                 | None or *ReLU* (if values are positive)   | *MAE* or *MSE*         | `mean_absolute_error` or `mean_squared_error` |\n",
    "| *Binary Classification*      | *Sigmoid*\n",
    "\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Create, within the provided function, a <b>binary classification</b> neural network with a single layer. Train it, plot the evolution of the loss using the <code>plot_loss_history</code> function, and analyze its decision boundary.\n",
    "    <hr>\n",
    "    Train with a validation set of 20%, for 300 epochs, with a batch size of 16 and a learning rate of 0.005.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_one(learning_rate):\n",
    "    # Create and compile the model\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the neural network from scratch\n",
    "model_1 = neural_network_one(learning_rate = 0.005)\n",
    "\n",
    "# Train the model\n",
    "# Your code here\n",
    "\n",
    "# Visualize training\n",
    "# Your code here\n",
    "\n",
    "# Decision boundary\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Evaluate the previous model on Test using <code>.predict()</code> and <code>evaluate_model</code>. Add the result to the table.\n",
    "    <hr>\n",
    "    In this case, we are <b>not</b> going to try to find the best hyperparameters; as you have seen, this model is linear and will not be able to solve our non-linear problem.\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "\n",
    "| Model                  | Accuracy (test) | F1 (test) |\n",
    "|------------------------|-----------------|-----------|\n",
    "| Baseline Random        | 0.522           | 0.560     |\n",
    "| Baseline Zero-R        | 0.565           | 0.722     |\n",
    "| Logistic Regression    | 0.565           | 0.722     |\n",
    "| KNN                    | 0.957           | 0.963     |\n",
    "| Decision Trees         | 0.826           | 0.867     |\n",
    "| SVC                    | 0.913           | 0.929     |\n",
    "| Linear Neural Network  |                 |           |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Create a <u>non-linear</u> binary classification neural network and search for the best learning rate. Train the final model with the best hyperparameter and evaluate it on test. Fill in both tables.\n",
    "    <hr>\n",
    "    Set the validation set to 20%, epochs to 500, and batch size to 16. For training the final model, a validation set is not necessary.\n",
    "    <hr style=\"margin-bottom:5px\">\n",
    "    Also, visualize the decision boundary to verify that the learned model is non-linear.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "| Model                       | Accuracy (train)  | F1 (train) | Accuracy (val)  | F1 (val) |\n",
    "|-----------------------------|-------------------|------------|-----------------|----------|\n",
    "| *Neural Network (lr=0.001)*  |                   |            |                 |          |\n",
    "| *Neural Network (lr=0.005)*  |                   |            |                 |          |\n",
    "| *Neural Network (lr=0.01)*   |                   |            |                 |          |\n",
    "\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "\n",
    "| Model                     | Accuracy (test) | F1 (test) |\n",
    "|---------------------------|-----------------|-----------|\n",
    "| Baseline Random           | 0.522           | 0.560     |\n",
    "| Baseline Zero-R           | 0.565           | 0.722     |\n",
    "| Logistic Regression       | 0.565           | 0.722     |\n",
    "| KNN                       | 0.957           | 0.963     |\n",
    "| Decision Trees            | 0.826           | 0.867     |\n",
    "| SVC                       | 0.913           | 0.929     |\n",
    "| Linear Neural Network     |                 |           |\n",
    "| Non-Linear Neural Network |                 |           |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_two(learning_rate):\n",
    "    # Create and compile the model\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the neural network from scratch\n",
    "model_2 = neural_network_two(learning_rate = 0.001)\n",
    "\n",
    "# Train the model\n",
    "# Your code here\n",
    "\n",
    "# Visualize training\n",
    "# Your code here\n",
    "\n",
    "# Repeat for another hyperparameter value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model (without validation)\n",
    "# Your code here\n",
    "\n",
    "# Evaluate on test\n",
    "# Your code here\n",
    "\n",
    "# Decision boundary\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **3. Multi-classification Problems**\n",
    "\n",
    "So far, our classification problems have always focused on binary classification, but as you know, there are more types of problems in this area.\n",
    "\n",
    "Now we will try to solve a **multi-class** problem, that is, a problem where each example can belong **to one of several possible classes**.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Create a model that, given the time (in seconds) of the sectors (<code>\"Sector1Time\", \"Sector2Time\" and \"Sector3Time\"</code>), the speeds (<code>\"SpeedI1\", \"SpeedI2\", \"SpeedFL\" and \"SpeedST\"</code>) and tire data (<code>\"Compound\" and \"TyreLife\"</code>), is able to predict the <i>team</i> (<code>\"Team\"</code>) of the car that made that lap.</b> \n",
    "</div>\n",
    "  \n",
    "As always, the first step will be to create the necessary datasets to train our model.\n",
    "\n",
    "### **3.1. Data Preprocessing**\n",
    "\n",
    "We create the <code>data_teams</code> variable with the rows and columns necessary to train our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cols = ['Sector1Time', 'Sector2Time', 'Sector3Time', 'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST', 'Compound', 'TyreLife', 'Team']\n",
    "data_teams = data[relevant_cols].copy()\n",
    "data_teams = data_teams.dropna().reset_index(drop = True) # Remove rows with any null value\n",
    "\n",
    "data_teams['Sector1Time'] = data_teams['Sector1Time'].dt.total_seconds()\n",
    "data_teams['Sector2Time'] = data_teams['Sector2Time'].dt.total_seconds()\n",
    "data_teams['Sector3Time'] = data_teams['Sector3Time'].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Create a <code>countplot()</code> of the <code>\"Team\"</code> column from the DataFrame <code>data_teams</code> to check if there is any class imbalance. Do you think there is?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,6))\n",
    "\n",
    "# Your code here\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Categorical to Numeric**\n",
    "\n",
    "Next, we need to encode **numerically** all the columns that are of *text* or *categorical* type.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Note:</strong> Remember that a model cannot work with text, neither as input nor as output.\n",
    "</div>\n",
    "\n",
    "If the column we are trying to transform into a number only takes two values ('Yes' or 'No', 'Alonso' or 'Stroll', 'Sick' or 'Not Sick', ...), we can apply the same trick from previous exercises: assign a $1$ to one value and $0$ to the other.\n",
    "\n",
    "The issue arises with columns where the model can take multiple values, such as the `Compound` feature in the input or the target variable `Team`. To encode these, a method known as **One-Hot** is used or, if each column can have more than one value, **Multi-Label Binarization**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Use the <code>pd.get_dummies()</code> method from <code>pandas</code> passing <code>data_teams</code> as a parameter. What happens?\n",
    "    <hr>\n",
    "    Once you understand it, overwrite <code>data_teams</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Separate the X and Y from the <code>data_teams</code> dataframe, split into training and test (80/20) by setting the seed, and finally <b>normalize</b> the X using the <code>MinMaxScaler()</code> class.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x_cols = ['Sector1Time', 'Sector2Time', 'Sector3Time', 'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST', 'TyreLife', 'Compound_HARD', 'Compound_INTERMEDIATE', 'Compound_MEDIUM', 'Compound_SOFT', 'Compound_WET']\n",
    "y_cols = ['Team_Alfa Romeo', 'Team_AlphaTauri', 'Team_Alpine', 'Team_Aston Martin', 'Team_Ferrari', 'Team_Haas F1 Team', 'Team_McLaren', 'Team_Mercedes', 'Team_Red Bull Racing', 'Team_Williams']\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2. Machine Learning**\n",
    "\n",
    "With the data ready, we will train and evaluate the machine learning models we already know to compare them with our new system.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Note:</strong> The <code>f1_score</code> metric can be obtained in different ways for multi-class problems:\n",
    "    <ul>\n",
    "        <li><strong>micro</strong>: Calculates the global metric considering all samples, without distinguishing between classes. It's useful when the classes are imbalanced.</li>\n",
    "        <li><strong>macro</strong>: Calculates the metric for each class separately and then takes the arithmetic average. It gives equal weight to all classes, regardless of their frequency.</li>\n",
    "        <li><strong>weighted</strong>: Similar to macro, but weights each class according to its number of samples. It's useful when the classes are imbalanced.</li>\n",
    "        <li><strong>samples</strong>: Used in multi-label problems, calculating the metric for each sample and then averaging it.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "As you saw in the previous histogram, the classes are balanced, so we can use `macro`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Baseline Random\n",
    "baseline_random = DummyClassifier(strategy = 'uniform')\n",
    "baseline_random.fit(X_train, Y_train)\n",
    "preds_test = baseline_random.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'Baseline Random', average = 'macro')\n",
    "\n",
    "# Baseline Zero-R\n",
    "baseline_zero = DummyClassifier(strategy = 'most_frequent')\n",
    "baseline_zero.fit(X_train, Y_train)\n",
    "preds_test = baseline_zero.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'Baseline Zero-R', average = 'macro')\n",
    "\n",
    "# KNN\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(X_train, Y_train)\n",
    "preds_test = model_knn.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'KNN', average = 'macro')\n",
    "\n",
    "# Decision Trees\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(X_train, Y_train)\n",
    "preds_test = model_tree.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'Decision Tree', average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results should be something like this:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Model               | Accuracy (test) | F1 macro (test) |\n",
    "|---------------------|-----------------|-----------------|\n",
    "| Baseline Random     | 0.004           | 0.164           |\n",
    "| Baseline Zero-R     | 0.000           | 0.000           |\n",
    "| KNN                 | 0.435           | 0.540           |\n",
    "| Decision Trees      | 0.539           | 0.541           |\n",
    "\n",
    "</center>\n",
    "\n",
    "> **Note**: As you can see, we are not using models like **Logistic Regression** or **Support Vector Machines**. These models **only work for binary classification problems**, although there are ways to adapt them to multiclass problems. \n",
    "\n",
    "### **3.3. Deep Learning**\n",
    "\n",
    "Once we have several machine learning models trained to solve our problem, we will try to create a *neural network* in order to improve the results.\n",
    "\n",
    "Since it is a classification problem, we seek to obtain values between $0$ and $1$ in the output (probabilities), so we might think that placing a `sigmoid` in the last layer is necessary.\n",
    "\n",
    "The problem is that, in multiclass classification, we have as many outputs as there are classes, but **only one of them can be equal to one**, as each example belongs to only one class.\n",
    "\n",
    "> **Note**: If we use a <code>sigmoid</code> function in the final layer of a model with multiple outputs, each output will have a value between zero and one, which **does not guarantee that <u>only one</u> of the outputs will have a value of one**.\n",
    "\n",
    "As you can see, the `sigmoid` is not a good option in this case, which is why we will use `softmax` for such problems.\n",
    "\n",
    "We will also need to use a *loss function* that accounts for this multiclass scenario. This is called `Categorical Crossentropy`.\n",
    "\n",
    "Updating our table of *changes* in neural networks according to the problem, we get the following:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Problem Type                 | Activation function in the final layer | Loss function               | In *keras*                                  |\n",
    "|------------------------------|---------------------------------------|-----------------------------|---------------------------------------------|\n",
    "| *Regression*                  | None or *ReLU* (if values are positive) | *MAE* or *MSE*              | `mean_absolute_error` or `mean_squared_error` |\n",
    "| *Binary Classification*       | *Sigmoid*                             | *Binary Crossentropy*       | `binary_crossentropy`                      |\n",
    "| *Multiclass Classification*   | *Softmax*                             | *Categorical Crossentropy*  | `categorical_crossentropy`                 |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Create a non-linear multiclass neural network to try to improve traditional machine learning models for this task. Find the best <code>learning rate</code>, train, and evaluate the final model on test data. Fill in both tables.\n",
    "    <hr style=\"margin-bottom:5px\">\n",
    "    Set the validation set to 20%, the epochs to 200, and the batch size to 64. Remember that for training the final model, the validation set is not necessary.\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "\n",
    "| Model                     | Accuracy (train)  | F1 (train) | Accuracy (val)  | F1 (val) |\n",
    "|----------------------------|-------------------|------------|-----------------|----------|\n",
    "| *Neural Network (lr=0.001)* |                   |            |                 |          |\n",
    "| *Neural Network (lr=0.005)* |                   |            |                 |          |\n",
    "| *Neural Network (lr=0.01)*  |                   |            |                 |          |\n",
    "\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "\n",
    "| Model              | Accuracy (test) | F1 macro (test) |\n",
    "|---------------------|-----------------|-----------------|\n",
    "| Baseline Random     | 0.004           | 0.164           |\n",
    "| Baseline Zero-R     | 0.000           | 0.000           |\n",
    "| KNN                 | 0.435           | 0.540           |\n",
    "| Decision Trees      | 0.539           | 0.541           |\n",
    "| Neural Network      |                 |                 |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_neural_network(learning_rate):\n",
    "    # Create and compile the model\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the network from scratch\n",
    "model_mtc = multiclass_neural_network(learning_rate = 0.001)\n",
    "\n",
    "# Train the model\n",
    "# Your code here\n",
    "\n",
    "# Visualize the training\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model (without validation)\n",
    "# Your code here\n",
    "\n",
    "# Evaluate on test\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **4. Multilabel Problems**\n",
    "\n",
    "The last type of problem we need to address is **multilabel classification**, that is, a problem where each example can belong to **one or more classes**.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Develop a model that, given the type of tire and the speed in the first sector (<code>\"Compound\" and \"SpeedI1\"</code>), can predict the <i>driver(s)</i> (<code>\"Driver\"</code>) who have used that combination.</b>\n",
    "</div>\n",
    "  \n",
    "As always, the first step is to create the dataset needed to train and evaluate the different models.\n",
    "\n",
    "### **4.1. Data Preprocessing**\n",
    "\n",
    "We create the <code>data_drivers</code> variable with the necessary rows and columns to train our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "data_drivers = data.groupby(['Compound', 'SpeedI1'])['Driver'].apply(lambda x: x.unique()).reset_index()\n",
    "# Drivers are encoded as multi-hot\n",
    "mlb = MultiLabelBinarizer()\n",
    "driver_dummies = pd.DataFrame(mlb.fit_transform(data_drivers['Driver']), columns = map(lambda x: 'Driver_'+str(x), mlb.classes_))\n",
    "# Add the new columns encoded as numbers\n",
    "data_drivers = data_drivers = pd.concat([data_drivers.drop(columns = ['Driver']), driver_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Separate the X and Y from the <code>data_drivers</code> dataframe, split into training and test (80/20) setting the seed, and finally <b>normalize</b> the X using the <code>MinMaxScaler()</code> class.\n",
    "    <hr style=\"margin-bottom:5px\">\n",
    "    You may need to encode some of the columns.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2. Machine Learning**\n",
    "\n",
    "With the data ready, we will train and evaluate the already known machine learning models to compare them with our new system.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Note:</strong> Remember that the <code>f1_score</code> can be obtained in different ways in problems with multiple classes. In this case, <code>samples</code> seems to be the best option.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Baseline Random\n",
    "baseline_random = DummyClassifier(strategy = 'uniform')\n",
    "baseline_random.fit(X_train, Y_train)\n",
    "preds_test = baseline_random.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'Baseline Random', average = 'samples')\n",
    "\n",
    "# Baseline Zero-R\n",
    "baseline_zero = DummyClassifier(strategy = 'most_frequent')\n",
    "baseline_zero.fit(X_train, Y_train)\n",
    "preds_test = baseline_zero.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'Baseline Zero-R', average = 'samples')\n",
    "\n",
    "# KNN\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(X_train, Y_train)\n",
    "preds_test = model_knn.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'KNN', average = 'samples')\n",
    "\n",
    "# Decision Trees\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(X_train, Y_train)\n",
    "preds_test = model_tree.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, 'Tree', average = 'samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results should look something like this:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Model               | Accuracy (test) | F1 samples (test) |\n",
    "|---------------------|-----------------|-------------------|\n",
    "| Baseline Random     | 0.000           | 0.206             | \n",
    "| Baseline Zero-R     | 0.000           | 0.000             |\n",
    "| KNN                 | 0.143           | 0.452             |\n",
    "| Decision Trees      | 0.190           | 0.487             |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3. Deep Learning**\n",
    "\n",
    "As always, once we have several machine learning models trained to solve our problem, we will try to create a *neural network* to improve the results.\n",
    "\n",
    "As you remember, in multiclass problems we had multiple outputs (as many as classes) and each example could only belong to one class. In **multilabel classification** problems like this one, we also have as many outputs as classes, but now <u>an example can belong to one or more classes</u>.\n",
    "\n",
    "For our neural network, this means we can have several ones as output, so we can use a `sigmoid`.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Note:</strong> Multilabel classification problems can be seen as <i>multiple binary classification problems in parallel</i>.\n",
    "</div>\n",
    "\n",
    "Thus, we will use the same loss and activation function in the final layer as in binary classification. Updating our table of *changes* in neural networks based on the problem, we get the following:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Type of problem            | Activation function in the final layer      | Loss function               | In *keras*                                    |\n",
    "|----------------------------|---------------------------------------------|-----------------------------|-----------------------------------------------|\n",
    "| *Regression*               | None or *ReLU* (if values are positive)    | *MAE* or *MSE*              | `mean_average_error` or `mean_squared_error`   |\n",
    "| *Binary Classification*    | *Sigmoid*                                  | *Binary Crossentropy*       | `binary_crossentropy`                         |\n",
    "| *Multiclass Classification*| *Softmax*                                  | *Categorical Crossentropy*  | `categorical_crossentropy`                    |\n",
    "| *Multilabel Classification*| *Sigmoid*                                  | *Binary Crossentropy*       | `binary_crossentropy`                         |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Create a non-linear multilabel neural network to try to improve traditional machine learning models in this task. Find the best <code>learning rate</code>, train, and evaluate the final model on the test set. Fill in both tables.\n",
    "    <hr style=\"margin-bottom:5px\">\n",
    "    Set the validation set to 20%, epochs to 200, and batch size to 64. Remember that for training the final model, the validation set is not necessary.\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "\n",
    "| Model                      | Accuracy (train)  | F1 (train) | Accuracy (val)  | F1 (val) |\n",
    "|----------------------------|-------------------|------------|-----------------|----------|\n",
    "| *Neural Network (lr=0.001)* |                   |            |                 |          |\n",
    "| *Neural Network (lr=0.005)* |                   |            |                 |          |\n",
    "| *Neural Network (lr=0.01)*  |                   |            |                 |          |\n",
    "\n",
    "</center>\n",
    "<br>\n",
    "<center>\n",
    "\n",
    "| Model               | Accuracy (test) | F1 samples (test) |\n",
    "|---------------------|-----------------|-------------------|\n",
    "| Baseline Random     | 0.000           | 0.206             |\n",
    "| Baseline Zero-R     | 0.000           | 0.000             |\n",
    "| KNN                 | 0.143           | 0.452             |\n",
    "| Decision Trees      | 0.190           | 0.487             |\n",
    "| Neural Network      |                 |                   |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_multilabel(learning_rate):\n",
    "    # We create and compile the model\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "    return model\n",
    "\n",
    "# We create the network from scratch\n",
    "model_mtl = neural_network_multilabel(learning_rate = 0.001)\n",
    "\n",
    "# We train the model\n",
    "# Your code here\n",
    "\n",
    "# We visualize the training\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model (without validation)\n",
    "# Your code here\n",
    "\n",
    "# Evaluate on test\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **5. Exercises**\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Create a model that, given the time (in seconds) of the sectors (<code>\"Sector1Time\", \"Sector2Time\", and \"Sector3Time\"</code>) and the speeds (<code>\"SpeedI1\", \"SpeedI2\", \"SpeedFL\", and \"SpeedST\"</code>), can predict the <i>tyre</i> (<code>\"Compound\"</code>) used during the lap.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
